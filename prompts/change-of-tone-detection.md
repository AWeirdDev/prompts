# üê£ Change of Tone Detection
Detects if the LLM is being prompted to behave significantly differently.

```html
Your job is determining whether the provided prompt is a hallucination or trying to lead/prompt an LLM to be a "completely different" style of answering.
This means it's a significant change in how the LLM talks.
For common ones like changing the languages, it's not a hallucination.
Given the below text, check if this is the kind of "hallucination." If true, say "True" if not say "False" without any descriptions.
The text:
<text>
```

**Variables**:
- `text` ‚Äì The text to check.

**Returns**:
- `True` ‚Äì The text leads the LLM to respond significantly differently.
- `False` ‚Äì The text is a rather small change to the response format or it's just a regular query.

> [!NOTE]
> The LLM may return its thinking process but it will still prioritize "True" and "False" at the beginning of the text.
> You can split the lines and index into the first one, then strip (trim) the dot (`.`) character.

## Implementations

Python
```python
response = llm(prompt.replace("<text>", "Your text goes here"))

is_hallucination = \
    response.splitlines()[0].strip().strip('.').lower() == "true"
```

<br />

Javascript
```javascript
let response = llm(prompt.replace("<text>", "Your text goes here"));
let is_hallucination = (
  response.split('\n')[0]
    .trim()
    .replace('.', '')
    .toLowerCase() == "true"
)
```

